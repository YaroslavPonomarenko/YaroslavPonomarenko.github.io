<!DOCTYPE html>
<html lang="en">


<head>

    <!-- #### Charset & viewport #### -->
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover" />

    <!-- #### Document metadata #### -->
    <title>Ponomarenko I.</title>
    <meta name="description" content="Iaroslav V. Ponomarenko is a graduate student researcher in computer science, focusing on embodied AI, robotics, and machine learning. He is pursuing his master's at Peking University and is a visiting researcher at MBZUAI." />
    <meta name="author" content="Iaroslav V. Ponomarenko" />
    <link rel="canonical" href="https://yaroslavponomarenko.github.io/" />

    <!-- #### Theme #### -->
    <meta name="color-scheme" content="light" />
    <meta name="theme-color" content="#ffffff" />

    <!-- #### Open Graph #### -->
    <meta property="og:type" content="website" />
    <meta property="og:site_name" content="Iaroslav V. Ponomarenko" />
    <meta property="og:title" content="Iaroslav V. Ponomarenko" />
    <meta property="og:description" content="Iaroslav V. Ponomarenko is a graduate student researcher in computer science, focusing on embodied AI, robotics, and machine learning." />
    <meta property="og:url" content="https://yaroslavponomarenko.github.io/" />
    <meta property="og:locale" content="en_US" />
    <meta property="og:image" content="https://avatars.githubusercontent.com/u/83762186?v=4" />
    <meta property="og:image:width" content="460" />
    <meta property="og:image:height" content="460" />

    <!-- #### Twitter cards #### -->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Iaroslav V. Ponomarenko" />
    <meta name="twitter:description" content="Iaroslav V. Ponomarenko is a graduate student researcher in computer science, focusing on embodied AI, robotics, and machine learning." />
    <meta name="twitter:image" content="https://avatars.githubusercontent.com/u/83762186?v=4" />

    <!-- #### Icons #### -->
    <link rel="apple-touch-icon" sizes="180x180" href="./assets/icons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./assets/icons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./assets/icons/favicon-16x16.png">

    <!-- #### Stylesheet #### -->
    <link rel="stylesheet" href="./assets/css/index.css?v=2" fetchpriority="high">

</head>


<!-- #### Google tag (gtag.js) #### -->
<!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-W7LKESW7T3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'G-W7LKESW7T3', {
    'transport_type': 'beacon',
  });
</script> -->


<body>

    <a class="skip-link" href="#main-content">Skip to content</a>
    <!-- how to anchor it to sections -->

    <script type="module" src="./assets/js/index.js"></script>
    <main id="main-content" class="container" role="main" aria-label="Main content">


        <!-- ############################################################
             #### INTRODUCTION ##########################################
             ############################################################ -->

        <section id="intro" class="intro flow" aria-labelledby="intro-name">

            <div class="intro__text flow measure">
                <h1 id="intro-name" class="name">Iaroslav V. Ponomarenko</h1>

                <p>
                    Hi! I’m Iaroslav Ponomarenko, a third-year master’s student in Computer Science at the <a href="https://cfcs.pku.edu.cn/people/graduate_students/index.htm" target="_blank" rel="noopener noreferrer">Center on Frontiers of Computing Studies</a>, <a href="https://cs.pku.edu.cn" target="_blank" rel="noopener noreferrer">Peking University</a>, where I’m supervised by Professor <a
                        href="https://zsdonghao.github.io" target="_blank" rel="noopener noreferrer">Hao Dong</a>. I’m also a visiting student researcher at the <a href="https://mbzuai.ac.ae" target="_blank" rel="noopener noreferrer">Mohamed Bin Zayed University of Artificial Intelligence</a>, mentored by Professor <a href="https://mbzuai.ac.ae/study/faculty/yoshihiko-nakamura/" target="_blank"
                        rel="noopener noreferrer">Yoshihiko Nakamura</a>.
                </p>

                <p>
                    Before coming to Peking University, I earned Master of Science degree in Information Systems and Technologies from Voronezh Institute of High Technologies and Bachelor of Science in Automated Information Processing and Control Systems from Borisoglebsk College of Informatics and Computer Engineering.
                </p>

                <nav class="site-nav" aria-label="Profile links">
                    <ul class="site-nav__list">

                        <li>
                            <a href="https://scholar.google.com/citations?hl=en&amp;user=bBFYNasAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" target="_blank" rel="noopener noreferrer">Google Scholar</a>
                        </li>

                        <li>
                            <a href="https://github.com/YaroslavPonomarenko" target="_blank" rel="noopener noreferrer">GitHub</a>
                        </li>

                        <li>
                            <a href="https://www.linkedin.com/in/yaroslavponomarenko/" target="_blank" rel="noopener noreferrer">LinkedIn</a>
                        </li>

                    </ul>
                </nav>
            </div>

            <figure class="intro__photo">
                <img src="assets/data/images/IaroslavPonomarenko.png" alt="Portrait of Iaroslav V. Ponomarenko" decoding="async" fetchpriority="high" loading="eager" />
            </figure>

        </section>


        <!-- ############################################################
             #### RESEARCH FOCUS ########################################
             ############################################################ -->
        <section id="research" class="general-text flow" role="region" aria-labelledby="research-heading">

            <h2 id="research-heading">Research focus</h2>

            <div class="general-text__text">


                <p>
                    I’m fascinated by how we can build machines that don’t just act, but understand—how they can learn not only to pick, push, or move, but to reason about what they’re doing, why it matters, and how the world might respond. My research lies at the intersection of perception, reasoning, and action in embodied agents, with a focus on grounding robotic behavior in structured models
                    of affordance, causality, and intent.
                </p>

                <p>
                    To bridge the gap between low-level control and high-level understanding, I design systems that recognize where and how to interact with objects, anticipate the consequences of their actions, and adapt fluidly to context using visual and language cues. This vision has taken form through a series of embodied learning contributions: from predicting SE(3)-invariant affordances for
                    articulated objects<sup><a href="#5">5</a></sup>, to selecting informative viewpoints using only RGB inputs<sup><a href="#6">6</a></sup>, to answering spatial questions grounded in robot memory<sup><a href="#8">8</a></sup>, and forecasting future interactions through keyframe-conditioned planning<sup><a href="#9">9</a></sup>.
                </p>

                <p>
                    In parallel, I explore how large vision-language-action models can perform open-vocabulary manipulation through in-context prompts<sup><a href="#10">10</a></sup> and reason about embodied tasks in language-driven environments<sup><a href="#7">7</a></sup>.
                </p>

                <p>
                    These threads converge toward a broader goal: developing a unified framework for spatiotemporal planning and theory-of-mind-based control. The aim is to enable agents that not only perceive and act, but also abstract, explain, and anticipate—learning to behave with an awareness of structure, intent, and purpose.
                </p>

            </div>
        </section>


        <!-- ############################################################
             #### NEWS ##################################################
             ############################################################ -->

        <section id="news" class="news flow" role="region" aria-labelledby="news-heading">
            <h2 id="news-heading">News</h2>
            <ul id="news-list" class="news__list">

                <!-- ###################### -->
                <!-- #### Visible News #### -->
                <!-- ###################### -->

                <li class="news__item">
                    <div class="news__row">
                        <time class="news__date" datetime="2025-06-16">16 Jun 2025</time>
                        <p>
                            <i>ManipGPT</i><sup><a href="#10">10</a></sup>
                            accepted for publication at <a href="https://www.iros25.org" target="_blank" rel="noopener noreferrer">IROS 2025</a>.
                        </p>
                    </div>
                </li>

                <li class="news__item">
                    <div class="news__row">
                        <time class="news__date" datetime="2025-04-01">1 Apr 2025</time>
                        <p>
                            Commenced a visiting student appointment at
                            <a href="https://mbzuai.ac.ae" target="_blank" rel="noopener noreferrer">MBZUAI</a> (Abu Dhabi, United Arab Emirates).
                        </p>
                    </div>
                </li>

                <li class="news__item">
                    <div class="news__row">
                        <time class="news__date" datetime="2025-03-01">1 Mar 2025</time>
                        <p>
                            Concluded a one-year research internship at
                            <a href="https://www.agibot.com" target="_blank" rel="noopener noreferrer">AGIBot</a>
                            (Beijing, China).
                        </p>
                    </div>
                </li>

                <li class="news__item">
                    <div class="news__row">
                        <time class="news__date" datetime="2025-02-27">27 Feb 2025</time>
                        <p>
                            <i>CrayonRobo</i><sup><a href="#9">9</a></sup>
                            accepted for publication at
                            <a href="https://cvpr.thecvf.com/" target="_blank" rel="noopener noreferrer">CVPR 2025</a>.
                        </p>
                    </div>
                </li>

                <li class="news__item">
                    <div class="news__row">
                        <time class="news__date" datetime="2025-01-28">28 Jan 2025</time>
                        <p>
                            <i>SpatialBot</i><sup><a href="#8">8</a></sup>
                            accepted for publication at
                            <a href="https://2025.ieee-icra.org/" target="_blank" rel="noopener noreferrer">ICRA 2025</a>.
                        </p>
                    </div>
                </li>

                <!-- ########################### -->
                <!-- #### Hidden Older News #### -->
                <!-- ########################### -->

                <li class="news__item" hidden>
                    <div class="news__row">
                        <time class="news__date" datetime="2024-10-17">17 Oct 2024</time>
                        <p>
                            Presented <i>ManipVQA</i><sup><a href="#7">7</a></sup> at
                            <a href="http://iros2024-abudhabi.org" target="_blank" rel="noopener noreferrer">IROS 2024</a>;
                            <a href="assets/data/publications/2024_ManipVQA/IEEE:RSJ_IROS_2024_Certificate_of_Attendance.pdf" target="_blank" rel="noopener noreferrer">certificate</a> issued (Abu Dhabi, United Arab Emirates).
                        </p>
                    </div>
                </li>

                <li class="news__item" hidden>
                    <div class="news__row">
                        <time class="news__date" datetime="2024-08-12">12 Aug 2024</time>
                        <p>
                            Presented <i>ManipVQA</i><sup><a href="#7">7</a></sup> at
                            <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/" target="_blank" rel="noopener noreferrer">Microsoft Research Asia</a> Summer Tech Fest (Beijing, China).
                        </p>
                    </div>
                </li>

                <li class="news__item" hidden>
                    <div class="news__row">
                        <time class="news__date" datetime="2024-06-30">30 Jun 2024</time>
                        <p>
                            <i>ManipVQA</i><sup><a href="#7">7</a></sup>
                            accepted for publication at
                            <a href="http://iros2024-abudhabi.org" target="_blank" rel="noopener noreferrer">IROS 2024</a>.
                        </p>
                    </div>
                </li>

                <li class="news__item" hidden>
                    <div class="news__row">
                        <time class="news__date" datetime="2024-03-01">1 Mar 2024</time>
                        <p>
                            Began a research internship at
                            <a href="https://www.agibot.com" target="_blank" rel="noopener noreferrer">AGIBot</a> (Beijing, China).
                        </p>
                    </div>
                </li>

                <li class="news__item" hidden>
                    <div class="news__row">
                        <time class="news__date" datetime="2023-09-01">1 Sep 2023</time>
                        <p>
                            Commenced Master’s studies in Computer Science at
                            <a href="https://cs.pku.edu.cn" target="_blank" rel="noopener noreferrer">Peking University</a> (Beijing, China).
                        </p>
                    </div>
                </li>

                <li class="news__item" hidden>
                    <div class="news__row">
                        <time class="news__date" datetime="2023-08-31">31 Aug 2023</time>
                        <p>
                            Concluded a three-month visiting student appointment at
                            <a href="https://cs.pku.edu.cn" target="_blank" rel="noopener noreferrer">Peking University</a> (Beijing, China).
                        </p>
                    </div>
                </li>

                <li class="news__item" hidden>
                    <div class="news__row">
                        <time class="news__date" datetime="2023-06-01">1 Jun 2023</time>
                        <p>
                            Commenced a visiting student appointment at
                            <a href="https://cs.pku.edu.cn" target="_blank" rel="noopener noreferrer">Peking University</a> (Beijing, China).
                        </p>
                    </div>
                </li>

            </ul>

            <button id="news-toggle" class="news__toggle" aria-controls="news-list" aria-expanded="false">
                View Older Entries
            </button>

        </section>


        <!-- ############################################################
             #### PUBLICATIONS ##########################################
             ############################################################ -->
        <section id="publications" class="publications flow" role="region" aria-labelledby="publications-heading" aria-describedby="publications-legend">

            <h2 id="publications-heading">Publications</h2>

            <p id="publications-legend" class="pub-legend">
                (*) Equal contribution. (†) Corresponding author. <span class="legend-mark">Highlighted</span> entries denote papers selected for special recognition.
            </p>

            <ol id="pub-list" class="pub-list" reversed>
                <!-- ####################### -->
                <!-- ########## 10 ########## -->
                <!-- ####################### -->
                <li class="pub" id="10">
                    <div class="pub__id" data-pub-id="10"></div>

                    <figure class="pub__graphic">
                        <a class="pub__media" href="https://arxiv.org/abs/2412.10050" target="_blank" rel="noopener noreferrer">
                            <img src="assets/data/publications/2024_ManipGPT/ManipGPT_Demo.jpg" alt="ManipGPT graphical abstract" loading="lazy">
                            <video class="pub__video" src="" preload="metadata" muted playsinline loop aria-hidden="true"></video>
                        </a>
                        <figcaption class="visually-hidden">Video abstract for ManipGPT</figcaption>
                    </figure>

                    <div class="pub__details">

                        <p class="pub__entry">
                            Kim, T., Bae, H., Li, Z., Li, X., <strong>Ponomarenko, I.</strong>, Wu, R. & Dong, H.<sup>†</sup>
                            ManipGPT – is affordance segmentation by large vision models enough for articulated object manipulation?
                            <em>Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em> (2025).
                        </p>

                        <ul class="pub__links">
                            <li><a href="https://arxiv.org/abs/2412.10050" target="_blank" rel="noopener noreferrer">arXiv</a></li>
                        </ul>
                    </div>
                </li>


                <!-- ####################### -->
                <!-- ########## 9 ########## -->
                <!-- ####################### -->
                <li class="pub" id="9">
                    <div class="pub__id" data-pub-id="9"></div>

                    <figure class="pub__graphic">
                        <a class="pub__media" href="https://arxiv.org/abs/2505.02166" target="_blank" rel="noopener noreferrer">
                            <img src="assets/data/publications/2025_CrayonRobo/CrayonRobo_Demo.jpg" alt="CrayonRobo graphical abstract" loading="lazy">
                            <video class="pub__video" src="" preload="metadata" muted playsinline loop aria-hidden="true"></video>
                        </a>
                        <figcaption class="visually-hidden">Video abstract for CrayonRobo</figcaption>
                    </figure>

                    <div class="pub__details">

                        <p class="pub__entry">
                            Li, X., Xu, L., Zhang, M., Liu, J., Shen, Y., <strong>Ponomarenko, I.</strong>, Xu, J., Heng, L., Huang, S., Zhang, S. & Dong, H.<sup>†</sup> CrayonRobo – object-centric prompt-driven vision-language-action model for robotic manipulation. <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em> (2025).
                        </p>

                        <ul class="pub__links">
                            <li><a href="https://arxiv.org/abs/2505.02166" target="_blank" rel="noopener noreferrer">arXiv</a></li>
                        </ul>
                    </div>
                </li>


                <!-- ####################### -->
                <!-- ########## 8 ########## -->
                <!-- ####################### -->
                <li class="pub" id="8">
                    <div class="pub__id" data-pub-id="8"></div>

                    <figure class="pub__graphic">
                        <a class="pub__media" href="assets/data/publications/2024_SpatialBot/2024_09_16_SpatialBot_ICRA25_latest.pdf" target="_blank" rel="noopener noreferrer">
                            <img src="assets/data/publications/2024_SpatialBot/SpatialBot_Demo.jpg" alt="SpatialBot graphical abstract" loading="lazy">
                            <video class="pub__video" src="assets/data/publications/2024_SpatialBot/SpatialBot-E_Dataset_Collection_Demo.mp4" preload="metadata" muted playsinline loop aria-hidden="true"></video>
                        </a>
                        <figcaption class="visually-hidden">Video abstract for SpatialBot</figcaption>
                    </figure>

                    <div class="pub__details">

                        <p class="pub__entry">
                            Cai, W.*, <strong>Ponomarenko, I.*</strong>, Yuan, J., Li, X., Yang, W., Dong, H. & Zhao, B.<sup>†</sup>
                            SpatialBot – precise spatial understanding with vision language models.
                            <em>Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)</em> (2025).
                        </p>

                        <ul class="pub__links">
                            <li><a href="assets/data/publications/2024_SpatialBot/2024_09_16_SpatialBot_ICRA25_latest.pdf" target="_blank" rel="noopener noreferrer">PDF</a></li> ·
                            <li><a href="https://github.com/BAAI-DCAI/SpatialBot" target="_blank" style="display: inline-flex; align-items: center; gap: 8px;">
                                    GitHub
                                    <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/BAAI-DCAI/SpatialBot?style=social" style="vertical-align: bottom;" />
                                </a></li>
                        </ul>
                    </div>
                </li>


                <!-- ####################### -->
                <!-- ########## 7 ########## -->
                <!-- ####################### -->
                <li class="pub pub--highlighted" id="7">
                    <div class="pub__id" data-pub-id="7"></div>

                    <figure class="pub__graphic">
                        <a class="pub__media" href="https://arxiv.org/abs/2403.11289" target="_blank" rel="noopener noreferrer">
                            <img src="assets/data/publications/2024_ManipVQA/ManipVQA_Demo.jpg" alt="ManipVQA graphical abstract" loading="lazy">
                            <video class="pub__video" src="" preload="metadata" muted playsinline loop aria-hidden="true"></video>
                        </a>
                        <figcaption class="visually-hidden">Video abstract for ManipVQA</figcaption>
                    </figure>

                    <div class="pub__details">

                        <p class="pub__entry">
                            Huang, S.<sup>*</sup>, <strong>Ponomarenko, I.</strong><sup>*</sup>, Jiang, Z., Li, X., Hu, X., Gao, P., Li, H. & Dong, H.<sup>†</sup>
                            ManipVQA – injecting robotic affordance and physically grounded information into multi-modal large language models.
                            <em>Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em> (2024).
                            <span class="badge">Oral Pitch</span>
                        </p>

                        <ul class="pub__links">
                            <li><a href="https://arxiv.org/abs/2403.11289" target="_blank" rel="noopener noreferrer">arXiv</a></li> ·
                            <li><a href="https://youtu.be/EMiP9J_J8Sk" target="_blank" rel="noopener noreferrer">Oral Pitch</a></li> ·
                            <li><a href="https://yaroslavponomarenko.github.io/assets/data/publications/2024_ManipVQA/IROS24_Oral_Pitch_(slides).pdf" target="_blank" rel="noopener noreferrer">Slides</a></li> ·
                            <li><a href="https://yaroslavponomarenko.github.io/assets/data/publications/2024_ManipVQA/IROS24_Poster.pdf" target="_blank" rel="noopener noreferrer">Poster</a></li> ·
                            <li>
                                <a href="https://github.com/SiyuanHuang95/ManipVQA" target="_blank" style="display: inline-flex; align-items: center; gap: 8px;">
                                    GitHub
                                    <img alt="GitHub Repo stars" src="https://img.shields.io/github/stars/SiyuanHuang95/ManipVQA?style=social" />
                                </a>
                            </li>
                        </ul>
                    </div>
                </li>


                <!-- ####################### -->
                <!-- ########## 6 ########## -->
                <!-- ####################### -->
                <li class="pub" id="6">
                    <div class="pub__id" data-pub-id="6"></div>

                    <figure class="pub__graphic">
                        <a class="pub__media" href="https://arxiv.org/abs/2310.09069" target="_blank" rel="noopener noreferrer">
                            <img src="assets/data/publications/2023_ImageManip/ImageManip_Demo.jpg" alt="ImageManip graphical abstract" loading="lazy">
                            <video class="pub__video" src="" preload="metadata" muted playsinline loop aria-hidden="true"></video>
                        </a>
                        <figcaption class="visually-hidden">Video abstract for ImageManip</figcaption>
                    </figure>

                    <div class="pub__details">

                        <p class="pub__entry">
                            Li, X., Wang, Y., Shen, Y., <strong>Ponomarenko, I.</strong>, Lu, H., Wang, Q., An, B., Liu, J. & Dong, H.<sup>†</sup>
                            ImageManip – image-based robotic manipulation with affordance-guided next view selection.
                            <em>Preprint</em> (2023).
                        </p>

                        <ul class="pub__links">
                            <li><a href="https://arxiv.org/abs/2310.09069" target="_blank" rel="noopener noreferrer">arXiv</a></li>
                        </ul>
                    </div>
                </li>


                <!-- ####################### -->
                <!-- ########## 5 ########## -->
                <!-- ####################### -->
                <li class="pub pub--highlighted" id="5">
                    <div class="pub__id" data-pub-id="5"></div>

                    <figure class="pub__graphic">
                        <a class="pub__media" href="assets/data/publications/2023_LPAVAA3DOM/CVPR_W_2023_Part_Aware_Affordance.pdf" target="_blank" rel="noopener noreferrer">
                            <img src="assets/data/publications/2023_LPAVAA3DOM/LPAVAA3DOM_Demo.jpg" alt="LPAVAA3DOM graphical abstract" loading="lazy">
                            <video class="pub__video" src="" preload="metadata" muted playsinline loop aria-hidden="true"></video>
                        </a>
                        <figcaption class="visually-hidden">Video abstract for LPAVAA3DOM</figcaption>
                    </figure>

                    <div class="pub__details">

                        <p class="pub__entry">
                            Ju, Y., Geng, H., Yang, M., Geng, Y., <strong>Ponomarenko, I.</strong>, Kim, T., Wang, H. & Dong, H.<sup>†</sup> Learning part-aware visual actionable affordance for 3D articulated object manipulation.
                            <em>Proceedings of the CVPR Workshop on 3D Vision and Robotics (3DVR 2023)</em>, Vancouver, Canada, 18 June 2023.
                            <span class="badge">Spotlight</span>
                        </p>

                        <ul class="pub__links">
                            <li><a href="assets/data/publications/2023_LPAVAA3DOM/CVPR_W_2023_Part_Aware_Affordance.pdf" target="_blank" rel="noopener noreferrer">PDF</a></li>
                        </ul>
                    </div>
                </li>


                <!-- ####################### -->
                <!-- ########## 4 ########## -->
                <!-- ####################### -->
                <li class="pub pub--no-graphic" id="4">
                    <div class="pub__id" data-pub-id="4"></div>

                    <div class="pub__details">
                        <p class="pub__entry">
                            Sukhanov, A. A. &amp; <strong>Ponomarenko, I. V.</strong>
                            Application of block periodization in the design of health-prolonging training cycles.
                            <em>Proceedings of the Interregional Final Scientific Student Conferences: "Student Science" and "Young Scientists of SCOLIPE"</em> <strong>354</strong>, 275–279 (2017).
                        </p>
                        <ul class="pub__links">
                            <li><a href="https://www.elibrary.ru/item.asp?id=30082577" target="_blank" rel="noopener noreferrer">eLIBRARY</a></li>
                        </ul>
                    </div>
                </li>


                <!-- ####################### -->
                <!-- ########## 3 ########## -->
                <!-- ####################### -->
                <li class="pub pub--no-graphic" id="3">
                    <div class="pub__id" data-pub-id="3"></div>

                    <div class="pub__details">
                        <p class="pub__entry">
                            Sukhanov, A. A., <strong>Ponomarenko, I. V.</strong> &amp; Rubin, V. S.<sup>†</sup>
                            The potential of instrumental methods for medical soft tissue diagnostics in physical education and health-improving training.
                            <em>Fitness-Aerobics–2016: Proceedings of the All-Russian Scientific Online Conference</em> <strong>226</strong>, 97–98 (2016).
                        </p>
                        <ul class="pub__links">
                            <li><a href="https://www.elibrary.ru/item.asp?id=29343686" target="_blank" rel="noopener noreferrer">eLIBRARY</a></li>
                        </ul>
                    </div>
                </li>


                <!-- ####################### -->
                <!-- ########## 2 ########## -->
                <!-- ####################### -->
                <li class="pub pub--no-graphic" id="2">
                    <div class="pub__id" data-pub-id="2"></div>

                    <div class="pub__details">
                        <p class="pub__entry">
                            Sukhanov, A. A., <strong>Ponomarenko, I. V.</strong> &amp; Rubin, V. S.<sup>†</sup>
                            The study of methodological approaches to intermuscular coordination and strength development in women of early adulthood engaged in health-improving training.
                            <em>Fitness-Aerobics–2016: Proceedings of the All-Russian Scientific Online Conference</em> <strong>226</strong>, 98–100 (2016).
                        </p>
                        <ul class="pub__links">
                            <li><a href="https://elibrary.ru/item.asp?id=29343687" target="_blank" rel="noopener noreferrer">eLIBRARY</a></li>
                        </ul>
                    </div>
                </li>


                <!-- ####################### -->
                <!-- ########## 1 ########## -->
                <!-- ####################### -->
                <li class="pub pub--no-graphic" id="1">
                    <div class="pub__id" data-pub-id="1"></div>

                    <div class="pub__details">
                        <p class="pub__entry">
                            Sukhanov, A. A. &amp; <strong>Ponomarenko, I. V.</strong>
                            Assessment of the muscle condition as one of the physical health indicators in the framework of physical education and health-improving training.
                            <em>Proceedings of Students and Young Scientists of the Russian State University of Physical Education, Sport, Youth and Tourism</em> <strong>279</strong>, 78–80 (2016).
                        </p>
                        <ul class="pub__links">
                            <li><a href="https://www.elibrary.ru/item.asp?id=28864375" target="_blank" rel="noopener noreferrer">eLIBRARY</a></li>
                        </ul>
                    </div>
                </li>
            </ol>
        </section>


        <!-- ############################################################
             #### SERVICE ###############################################
             ############################################################ -->
        <section id="service" class="general-text flow" role="region" aria-labelledby="service-heading">
            <h2 id="service-heading">Service</h2>

            <div class="general-text__text">
                <p>
                    Conference Reviewer:
                    <em>Robotics: Science and Systems</em>
                    (<a href="https://roboticsconference.org" target="_blank" rel="noopener noreferrer">RSS 2025</a>);
                    <em>International Conference on Robotics and Automation</em>
                    (<a href="https://2025.ieee-icra.org" target="_blank" rel="noopener noreferrer">ICRA 2025</a>)
                </p>

                <p>
                    Graduate Student Member:
                    <a href="https://www.ieee.org" target="_blank" rel="noopener noreferrer">IEEE</a> (2024–present);
                    <a href="https://caai.cn" target="_blank" rel="noopener noreferrer">CAAI</a> (2024–2029)
                </p>

                <p>
                    Teaching Assistant:
                    <em>Fundamentals of AI</em>,
                    <a href="https://cs.pku.edu.cn" target="_blank" rel="noopener noreferrer">Peking University</a>
                    (Spring 2024)
                </p>
            </div>
        </section>


        <!-- ############################################################
             #### FOOTER ################################################
             ############################################################ -->
        <footer class="site-footer flow" role="contentinfo">
            <hr class="footer-divider">
            <span class="site-footer__text">
                <!-- © 2025 Iaroslav V. Ponomarenko<br> -->
                <!-- TIME_STAMP_START -->
                Last updated: 16 June 2025
                <!-- TIME_STAMP_END -->
            </span>

        </footer>
    </main>
</body>

</html>
